[2024-04-21T14:19:21.354+0000] {logging_mixin.py:188} INFO - Changing /opt/***/logs/dag_id=dag_for_news/run_id=manual__2024-04-21T14:19:15.001586+00:00/task_id=model_prediction_data permission to 509
[2024-04-21T14:19:21.385+0000] {logging_mixin.py:188} INFO - Changing /opt/***/logs/dag_id=dag_for_news/run_id=manual__2024-04-21T14:19:15.001586+00:00/task_id=model_prediction_data permission to 509
[2024-04-21T14:19:21.416+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_for_news.model_prediction_data manual__2024-04-21T14:19:15.001586+00:00 [queued]>
[2024-04-21T14:19:21.424+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_for_news.model_prediction_data manual__2024-04-21T14:19:15.001586+00:00 [queued]>
[2024-04-21T14:19:21.425+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2024-04-21T14:19:21.439+0000] {taskinstance.py:2192} INFO - Executing <Task(DockerOperator): model_prediction_data> on 2024-04-21 14:19:15.001586+00:00
[2024-04-21T14:19:21.445+0000] {standard_task_runner.py:60} INFO - Started process 112 to run task
[2024-04-21T14:19:21.449+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'dag_for_news', 'model_prediction_data', 'manual__2024-04-21T14:19:15.001586+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/classificator.py', '--cfg-path', '/tmp/tmpyswwsicm']
[2024-04-21T14:19:21.452+0000] {standard_task_runner.py:88} INFO - Job 4: Subtask model_prediction_data
[2024-04-21T14:19:21.497+0000] {logging_mixin.py:188} INFO - Changing /opt/***/logs/dag_id=dag_for_news/run_id=manual__2024-04-21T14:19:15.001586+00:00/task_id=model_prediction_data permission to 509
[2024-04-21T14:19:21.505+0000] {task_command.py:423} INFO - Running <TaskInstance: dag_for_news.model_prediction_data manual__2024-04-21T14:19:15.001586+00:00 [running]> on host 1a58708e393f
[2024-04-21T14:19:21.573+0000] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_for_news' AIRFLOW_CTX_TASK_ID='model_prediction_data' AIRFLOW_CTX_EXECUTION_DATE='2024-04-21T14:19:15.001586+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-04-21T14:19:15.001586+00:00'
[2024-04-21T14:19:21.585+0000] {docker.py:359} INFO - Starting docker container from image model_prediction_data2:latest
[2024-04-21T14:20:02.491+0000] {docker.py:429} INFO - /usr/local/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
[2024-04-21T14:20:15.091+0000] {docker.py:429} INFO - Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'forced_eos_token_id': 2}
[2024-04-21T14:21:02.117+0000] {docker.py:429} INFO - Registered model 'Crypto_news' already exists. Creating a new version of this model...
[2024-04-21T14:21:02.149+0000] {docker.py:429} INFO - 2024/04/21 14:21:02 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Crypto_news, version 2
Created version '2' of model 'Crypto_news'.
[2024-04-21T14:21:34.756+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=dag_for_news, task_id=model_prediction_data, execution_date=20240421T141915, start_date=20240421T141921, end_date=20240421T142134
[2024-04-21T14:21:34.844+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-04-21T14:21:34.916+0000] {taskinstance.py:3281} INFO - 1 downstream tasks scheduled from follow-on schedule check
